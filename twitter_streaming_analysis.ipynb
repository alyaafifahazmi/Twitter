{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%run mod_twitter_streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_json('twitter.json')              # save file name as twitter in mod_twitter_streaming file\n",
    "pd.set_option('display.max_columns', 500)        # to display all columns\n",
    "#pd.set_option('display.max_colwidth', -1)       # to display everything in cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "twitter = data.loc[:,['text','source', 'possibly_sensitive','retweet_count', 'favorite_count','display_text_range', 'lang']]\n",
    "twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "language = twitter.groupby('lang', as_index = False).count()\n",
    "language = pd.DataFrame(language)\n",
    "language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (15,7))\n",
    "twitter.groupby('lang').text.count().plot.bar(ax=ax, color = 'skyblue').grid()\n",
    "plt.title('Languages used in Twitter')\n",
    "plt.xlabel('Languages')\n",
    "plt.ylabel('Counts of tweets')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = data['text']\n",
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_features(text):   \n",
    "    \n",
    "    text = re.sub('(@)\\w+', '', text)              # Removing @mentions\n",
    "    text = re.sub('RT :', '', text)                # Removing RT \n",
    "    text = re.sub('https?://\\S+', '', text)        # Removing hyperlink\n",
    "    text = text.lower()                            # Lowercase everything\n",
    "    text = re.sub(r'[^A-Za-z0-9 ]+', '', text)     # Keep alphanumeric and space only \n",
    "    \n",
    "    return text\n",
    "\n",
    "tweets = tweets.apply(remove_features)\n",
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splits all the sentences up which makes it easier to work with\n",
    "\n",
    "all_sentences = []\n",
    "\n",
    "for word in tweets:\n",
    "   all_sentences.append(word) \n",
    "\n",
    "all_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = list()\n",
    "\n",
    "for line in all_sentences:\n",
    "    words = line.split()\n",
    "    for w in words:\n",
    "        lines.append(w)\n",
    "        \n",
    "print(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines2 = []\n",
    "\n",
    "for word in lines:\n",
    "    if word != '':\n",
    "        lines2.append(word)\n",
    "        \n",
    "lines2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is stemming the words to their root\n",
    "\n",
    "import nltk\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "#using lemmatizer instead of stemmer as many last letter 'e' at the end of the words are removed\n",
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "stem = []\n",
    "for word in lines2:\n",
    "    stem.append(wnl.lemmatize(word))\n",
    "    \n",
    "stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing stop words\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "stem2 = []\n",
    "\n",
    "#for word in stem:\n",
    "#    if word not in nlp.Defaults.stop_words:\n",
    "#        stem2.append(word)\n",
    "\n",
    "for w in stem:\n",
    "    if w not in stop_words:\n",
    "        stem2.append(w)\n",
    "stem2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = pd.DataFrame(stem2)\n",
    "words = words[0].value_counts()\n",
    "\n",
    "words.sort_values(ascending=False)\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt; plt.rcdefaults()\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop words that doesnt make sense from lemmetization\n",
    "\n",
    "words = words.drop(['de', 'amp'])\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To show the top 20 words being used\n",
    "\n",
    "words = words[:20,]\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.barplot(words.values, words.index, alpha=0.8)\n",
    "plt.title('Top Words Overall')\n",
    "plt.ylabel('Word from Tweet', fontsize=12)\n",
    "plt.xlabel('Count of Words', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "str1 = \" \" \n",
    "stem2 = str1.join(lines2)\n",
    "\n",
    "stem2 = nlp(stem2)\n",
    "\n",
    "label = [(X.text, X.label_) for X in stem2.ents]\n",
    "\n",
    "data_word_entity = pd.DataFrame(label, columns = ['Word','Entity'])\n",
    "\n",
    "data_word_entity = data_word_entity.where(data_word_entity['Entity'] == 'PERSON')\n",
    "\n",
    "data_name = data_word_entity['Word'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = data_name[:10,]\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.barplot(data_name.values, data_name.index, alpha=0.8)\n",
    "plt.title('Top People Mentioned')\n",
    "plt.ylabel('Word from Tweet', fontsize=12)\n",
    "plt.xlabel('Count of Words', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_word_entity.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "People mentioned analysis is not relevant due to languages other than english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "# Create a function to get the subjective or opinionated the text is\n",
    "\n",
    "def getSubjectivity(text):\n",
    "   return TextBlob(text).sentiment.subjectivity\n",
    "\n",
    "# Create a function to get the polarity, positive/negative the text is\n",
    "\n",
    "def getPolarity(text):\n",
    "   return  TextBlob(text).sentiment.polarity\n",
    "\n",
    "\n",
    "# Create two new columns 'Subjectivity' & 'Polarity'\n",
    "\n",
    "data['Subjectivity'] = data['text'].apply(getSubjectivity)\n",
    "data['Polarity'] = data['text'].apply(getPolarity)\n",
    "\n",
    "# Show the new dataframe with columns 'Subjectivity' & 'Polarity'\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to compute negative (-1), neutral (0) and positive (+1) analysis\n",
    "\n",
    "def getAnalysis(score):\n",
    "    if score < 0:\n",
    "      return 'Negative'\n",
    "    elif score == 0:\n",
    "      return 'Neutral'\n",
    "    else:\n",
    "      return 'Positive'\n",
    "\n",
    "data['Analysis'] = data['Polarity'].apply(getAnalysis)\n",
    "# Show the dataframe\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Analysis.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (0, data.shape[0]):\n",
    "    plt.scatter(data[\"Polarity\"][i], data[\"Subjectivity\"][i], color = 'Orange')\n",
    "\n",
    "plt.title('Sentiment Analysis')\n",
    "plt.grid()\n",
    "plt.xlabel('Polarity')\n",
    "plt.ylabel('Subjectivity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting and visualizing the counts\n",
    "plt.title('Sentiment Analysis')\n",
    "plt.xlabel('Sentiment')\n",
    "plt.ylabel('Counts')\n",
    "data['Analysis'].value_counts().plot(kind = 'bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Word cloud visualization\n",
    "#allWords = ' '.join([twts for twts in str(tweets)])\n",
    "wordCloud =  WordCloud(width = 500, height = 300, random_state = 21, max_font_size = 110).generate(str(tweets))\n",
    "\n",
    "plt.imshow(wordCloud, interpolation = \"bilinear\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
